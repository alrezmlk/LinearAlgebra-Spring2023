# Linear Algebra Course Project: NLP and Computer Vision Applications

This repository contains project work for a Linear Algebra course, applying linear algebra concepts to tasks in NLP and computer vision. The project is divided into two main parts:
1. **NLP Task**: Word embedding and word cloud generation.
2. **Computer Vision Task**: Image compression using Singular Value Decomposition (SVD).

Repository Link: [GitHub Repository](https://github.com/alrezmlk/LinearAlgebra-Spring2023)

---

## Table of Contents
- [Project Overview](#project-overview)
- [Part 1: NLP Task - Word Embedding and Word Cloud](#part-1-nlp-task---word-embedding-and-word-cloud)
- [Part 2: Computer Vision Task - Image Compression with SVD](#part-2-computer-vision-task---image-compression-with-svd)
- [Homework](#homework)


---

## Project Overview

This course project explores applications of linear algebra in natural language processing (NLP) and computer vision:
- **NLP Task**: Embedding words from a dataset into vector space and visualizing word associations in a word cloud.
- **Computer Vision Task**: Compressing images using SVD, a matrix factorization method widely used in linear algebra for dimensionality reduction.

---

## Part 1: NLP Task - Word Embedding and Word Cloud

In this part, we explore word embeddings to represent words in a vector space, allowing us to analyze relationships between them. The embeddings are then visualized in the form of a word cloud to illustrate word frequency and relevance.

Steps involved:
1. **Word Embedding**: Vectorizing words from the provided dataset to capture semantic relationships.
2. **Word Cloud Generation**: Creating a word cloud to visualize word prominence and association.

---

## Part 2: Computer Vision Task - Image Compression with SVD

This part demonstrates the application of **Singular Value Decomposition (SVD)** in compressing images. SVD is a technique that decomposes a matrix into three components, which can be used to approximate the original image while reducing the file size.

Steps involved:
1. **SVD Factorization**: Decomposing the image matrix into three matrices (U, Î£, and V).
2. **Image Reconstruction**: Reconstructing the image with fewer singular values to achieve compression, balancing quality and file size.

---

## Homework

This repository also includes homework assignments related to linear algebra concepts applied to NLP and computer vision. These assignments deepen the understanding of the mathematical principles behind:
- **Vector Representations**: Using linear transformations for word embeddings.
- **Matrix Factorization**: Understanding the theory and practical implementation of SVD for image compression.

Each homework assignment includes theoretical questions and coding exercises to reinforce course concepts.

---

## Installation

To run the notebooks, follow these steps:

1. **Clone this repository**:
   ```bash
   git clone https://github.com/alrezmlk/LinearAlgebra-Spring2023.git
   cd LinearAlgebra-Spring2023
